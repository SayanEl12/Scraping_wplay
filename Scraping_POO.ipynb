{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scraping**\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraccion de datos\n",
    "- equipos -> [[equipos_locales], [equipos_visitantes]]\n",
    "- cuotas -> [[cuota_local, cuota_empate, cuota_visitante]] \n",
    "- fecha_hora -> [[fecha], [hora]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraping:\n",
    "    def __init__(self, urls) -> None:\n",
    "        for url in urls:\n",
    "            print(f\"analizando >>{url}<<\")\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, 'lxml')\n",
    "            self.container = soup.find('div', class_='fragment expander coupon-for-type')\n",
    "\n",
    "            duplicade_links = [elem.get(\"href\") for elem in self.container.find_all('a', title=\"NÃºmero de mercados\")]\n",
    "            self.links_per_match = [] \n",
    "    \n",
    "            for item in duplicade_links:\n",
    "                if item not in self.links_per_match:\n",
    "                    self.links_per_match.append(item)\n",
    "\n",
    "    def equipos(self):\n",
    "        local_vist = []\n",
    "        equipos = [elem.text for elem in self.container.find_all('span', class_='seln-name')]\n",
    "        locales = equipos[::2]\n",
    "        visitantes = equipos[1::2]\n",
    "        for i in range(len(locales)):\n",
    "            match = [locales[i], visitantes[i]]\n",
    "            local_vist.append(match)\n",
    "        return local_vist\n",
    "    \n",
    "    def cuotas(self):\n",
    "        puntos = [elem.text for elem in self.container.find_all('span', class_='price dec')]\n",
    "        cuotas = [puntos[i:i+3] for i in range(0, len(puntos), 3)]\n",
    "        return cuotas\n",
    "    \n",
    "    def hora_fecha(self):\n",
    "        meses = {'Ene': '01', 'Feb': '02', 'Mar': '03', 'Abr': '04', 'May': '05', 'Jun': '06',\n",
    "             'Jul': '07', 'Ago': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dic': '12'}\n",
    "        horarios = []\n",
    "        datos = pd.DataFrame(columns=['hora', 'fecha'])\n",
    "        eventos = self.container.find_all('div', {'class': 'ev'})\n",
    "        for evento in eventos:\n",
    "            hora_element = evento.find('span', {'class': 'time'})\n",
    "            fecha_element = evento.find('span', {'class': 'date'})\n",
    "\n",
    "            if hora_element and fecha_element:\n",
    "                hora = hora_element.text\n",
    "                fecha = fecha_element.text\n",
    "                fecha = fecha + ' 2023'\n",
    "                fecha = fecha.replace(fecha.split()[1], meses[fecha.split()[1]])\n",
    "                fecha_hora = fecha + ' ' + hora\n",
    "                fecha_hora = datetime.strptime(fecha_hora, '%d %m %Y %H:%M')\n",
    "                fecha_hora = datetime.strftime(fecha_hora, '%Y-%m-%d %H:%M')\n",
    "                horarios.append(str(fecha_hora).split(' '))\n",
    "        return horarios\n",
    "    \n",
    "    def dobles_oportunidades(self):\n",
    "        dobles_oportunidades = []\n",
    "        for link in self.links_per_match:\n",
    "            try:\n",
    "                new_url = \"https://apuestas.wplay.co\" + link\n",
    "                new_page = requests.get(new_url)\n",
    "                new_soup = BeautifulSoup(new_page.content, 'lxml')\n",
    "                new_container = new_soup.find('ul', class_='default mkt_content limited mkt-sort-DBLC ev-sort-MT')\n",
    "                group = [elem.text for elem in new_container.find_all('span', class_=\"price dec\")]\n",
    "                dobles_oportunidades.append(group)\n",
    "            except AttributeError:\n",
    "                print(f\".  el link: -- {new_url} -- no contiene dobles_oportunidades\")\n",
    "                dobles_oportunidades.append([\"N/A\",\"N/A\", \"N/A\"])\n",
    "        return dobles_oportunidades\n",
    "    \n",
    "    def ambos_anotan(self):\n",
    "        si_no = []\n",
    "        for link in self.links_per_match:\n",
    "            try:\n",
    "                new_url = \"https://apuestas.wplay.co\" + link\n",
    "                new_page = requests.get(new_url)\n",
    "                new_soup = BeautifulSoup(new_page.content, 'lxml')\n",
    "                new_container = new_soup.find('table', class_='horizontal mkt_content mkt-sort-BTSC')\n",
    "                group = [elem.text for elem in new_container.find_all('span', class_=\"price dec\")]\n",
    "                si_no.append(group)\n",
    "            except AttributeError:\n",
    "                print(f\".  el link: -- {new_url} -- no contiene ambos_anotan\")\n",
    "                si_no.append([\"N/A\",\"N/A\"])\n",
    "        return si_no\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creacion del excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Create_Excel(Scraping):\n",
    "    def __init__(self, urls) -> None:\n",
    "        super().__init__(urls)\n",
    "        \n",
    "        equipos = self.equipos()\n",
    "        cuotas = self.cuotas()\n",
    "        hora_fecha = self.hora_fecha()\n",
    "        dobles_oportunidades = self.dobles_oportunidades()\n",
    "        si_no = self.ambos_anotan()\n",
    "        total_data = zip(equipos, cuotas, hora_fecha,\n",
    "                        dobles_oportunidades, si_no)\n",
    "        COLUMNS = ['local', 'vist', 'cuo_local', 'cuo_emp', 'cuo_vist', 'fecha', 'hora',\n",
    "                   'local_emp', 'local_vist', 'vist_emp', 'si_anotan', 'no_anotan']\n",
    "        self.Excel(total_data, COLUMNS)\n",
    "\n",
    "    def Excel(self, total_data, order):\n",
    "        partidos_totales = []\n",
    "        partido = []\n",
    "        for i in total_data:\n",
    "            local, vist = i[0]\n",
    "            cuo_local, cuo_emp, cuo_vist = i[1]\n",
    "            fecha, hora = i[2]\n",
    "            local_emp, local_vist, vist_emp = i[3]\n",
    "            si_anotan, no_anotan = i[4]\n",
    "            datos_part = (local, vist, cuo_local, cuo_emp, cuo_vist, fecha, hora,\n",
    "                          local_emp, local_vist, vist_emp, si_anotan, no_anotan)\n",
    "            partido.append(datos_part)\n",
    "        partidos_totales.extend(partido)\n",
    "\n",
    "        df = pd.DataFrame(partidos_totales, columns=order)\n",
    "        nuevos_nombre = {\n",
    "            'vist':'visitante',\n",
    "            'cuo_local':'cuota_local',\n",
    "            'cuo_emp':'cuota_empate',\n",
    "            'cuo_vist':'cuota_visitante',\n",
    "            'local_emp':'local/empate',\n",
    "            'local_vist':'local/visitante',\n",
    "            'vist_emp':'visitante/empate'\n",
    "        }\n",
    "        df = df.rename(columns=nuevos_nombre)\n",
    "\n",
    "        writer = pd.ExcelWriter('cuotas.xlsx', engine='xlsxwriter')\n",
    "        df.to_excel(writer, sheet_name='Cuotas_1', index=False)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analizando >>https://apuestas.wplay.co/es/Ligue1<<\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://apuestas.wplay.co/es/Ligue1']\n",
    "\n",
    "obj = Create_Excel(urls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
